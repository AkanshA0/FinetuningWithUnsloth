{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afad369",
   "metadata": {
    "id": "9afad369"
   },
   "source": [
    "# Colab 5: Continued Pretraining on a New Language\n",
    "\n",
    "This notebook shows how to perform continued pretraining using Unsloth to teach the model a new language.\n",
    "\n",
    "Dataset: using small small subset of https://www.kaggle.com/datasets/abhishek/hindi-oscar-corpus/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a29ee9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24a29ee9",
    "outputId": "19f18a4c-ff56-4fac-d25d-052d2eeb1ab3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m351.3/351.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m136.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q unsloth transformers datasets accelerate bitsandbytes peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2034e423",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2034e423",
    "outputId": "81559f6e-09b5-46e4-cbf8-a215a700cedb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62f9cebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62f9cebc",
    "outputId": "68dd6ae4-17ec-43b6-b2e9-abd57f46e5e0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded lines: 100000\n",
      "Example: à¤¶à¤¾à¤°à¤¦à¤¾ à¤ªà¤¾à¤°à¤¾ à¤•à¥‡ à¤®à¤¿à¤²à¤¨ à¤šà¥ˆià¤• à¤¸à¥‡ à¤†à¤œ à¤®à¤¹à¤¾à¤ªà¥Œà¤° à¤¦à¥‡à¤µà¥‡à¤¨à¥à¤¦à¥à¤° à¤¯à¤¾à¤¦à¤µ, à¤ªà¤¾à¤°à¥à¤·à¤¦ à¤›à¥‹à¤Ÿà¥‡ à¤²à¤¾à¤² à¤šà¥ˆà¤§à¤°à¥€ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤µà¤¾à¤°à¥à¤¡ à¤•à¤¾ à¤­à¥à¤°à¤®à¤£ à¤•à¤°à¤¤à¥‡ à¤¹à¥à¤ à¤µà¤¾à¤°à¥à¤¡ à¤•à¥€ à¤ªà¥‡à¤¯à¤œà¤², à¤¸à¥à¤µà¤šà¥à¤›à¤¤à¤¾ à¤¸à¤«à¤¾à¤ˆ, à¤µà¤¿à¤•à¤¾à¤¸ à¤•à¤¾à¤°à¥à¤¯à¥‹à¤‚ à¤•à¤¾ à¤¨à¤¿à¤°à¥€à¤•à¥à¤·à¤£ à¤•à¤¿à¤¯à¤¾à¥¤\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 100000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "file_name = \"hindi_small.txt\"\n",
    "\n",
    "# Read lines from your uploaded text file\n",
    "with open(\"hindi_small.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(\"Loaded lines:\", len(lines))\n",
    "print(\"Example:\", lines[0])\n",
    "\n",
    "# Create a Hugging Face Dataset object\n",
    "text_ds = Dataset.from_dict({\"text\": lines})\n",
    "print(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9a9883",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447,
     "referenced_widgets": [
      "59936955b20743dfa9f8b67003be7845",
      "76016149df8a42bf8540af3bff4afc04",
      "89bb5a2fefc44fe0a513953241604b8b",
      "dfb857e3d1c846aaa63c540496d689d7",
      "8be188aa1d5044bfb759fca51ca1c035",
      "48e3a98d0ed942368b8afb317c58c7f2",
      "e0252b6cc296465facd18f841355dfaa",
      "d721c03b1ae6416d946db9320d7afc67",
      "0c0e6c8b8278475ea1f742b2145e0d86",
      "3a42888318ce4a2db82f6a7ec1575240",
      "7eb01ef612e040f183de3e461c330e79",
      "fc3c36fc9b534c86bc7af600b9e1382a",
      "78d7d41a88ee4dd989c0e6be9d38e3d0",
      "33dec6163df74b89ac59b39650cda497",
      "cad920e4b63e4be58cdfbee13be3c6d1",
      "3485ef1885524859a3d1d46ae8e69b87",
      "af0e6b38871e46eda3fb949ba50e175b",
      "2b176f1a95844db292e548a1c0818c2d",
      "7e126c2d9d3e47d6918cca742d804fed",
      "079a90d32b5a44b4b03de79b3468b9b6",
      "88b2edf7b1684d89b8651d7628f16b32",
      "ff32eea4ee254422aede004149875516",
      "1d35760966bc48ad8602333f83060c57",
      "714bc2ec431e4920b944453f1aabe7b6",
      "dbec5006031840b1b6c02798d20eb423",
      "e3fed704b014404eb5c71d6df3973a47",
      "e360dcd4b0304ef6b949fd4aa53f6a5a",
      "9b31013c22be4372b6e435e13059bebc",
      "75389d15428e41bc988c83ebf7b2b8ad",
      "5a91c21800ff4620bfb8fe64881c7f70",
      "e512d9c6ca44416abf4acbb6a1ff4636",
      "b6a2973be415445bae98558dbc900831",
      "06b29ac1bd6942e9a35d23d65264d235",
      "e150cf7577754fcdb0ae7b2d1b9cd42d",
      "e930bbc322e64b78bc4a055d2ad382e4",
      "edfdbfdcb168489e98fe2431f3320694",
      "c0ef912b209244548726a58618f3d907",
      "343780ceda444775bab97dec3a0528c9",
      "1ef5d828c93f450696e237edc90a1a85",
      "2e4e95d5e63a46a6a9012e885f386403",
      "4e3339b214d84a2e81d6cf8b6a2bbc91",
      "aa37ee4d64484d40942dbaa120f289ac",
      "3aca89e130a641ce816cd9ab62b79207",
      "162e3cbb9b504389a39ed6f4e2f8e3b1",
      "ec0711350cf848fb839806e318b83298",
      "400fac7d434c448b82fe0e5932b3581a",
      "d1d7d7088b114101afd75adce7d0b80c",
      "e307bff20cb143bf8eadb86ba0b2a2e7",
      "a9693f07b2c148dd89f2540ac4909b82",
      "f7311b9dfc0d47158765ffdf094be3d0",
      "9e35a1928fb746e6be063a40634ed574",
      "73b27a0ff40044f9b0ea4f5932669633",
      "5190a26b86fe48369f36707e93e7a52f",
      "8ee2f27de1664b7ea84a2ce6aed0f758",
      "f08ae2264cd74b23b5ca879e5855bc17",
      "ae52abee96f945408cf06621b733caec",
      "db447d785d914971bd8e8c6750bc319f",
      "edb8994ef52644e6bf51e3a997073e72",
      "b17a7bd3315c42e994b839f1d2d054e7",
      "3f0818bbef8d42848809921438368df6",
      "92e0487bdffb4c35bea5bd1324b0e932",
      "19cec56f6f314056bfdb6feaf1486637",
      "94c685fe8d89421eb70cdd333c7db7c5",
      "d6ac8f03b160468f8fc4ae6dc91d030e",
      "3b1b7226c28f4d179fc6677659e564c4",
      "efce22e2b3c74b2f88395a341423a08c",
      "b1d8cdd394004cca86a5ff7449361f3f",
      "35f684865bda4eefbd89961459a11505",
      "cf6055e3fc2d4fcebe9b80f971dce576",
      "0144e859c02b4f60bef4dd6a5372c70e",
      "3d46b65f9a6e467cb85ff856ff4af83d",
      "b7a50d5fd3b049bc97537d33ea436db1",
      "4839691fb55a46ad9c7e01b7992c8421",
      "2303b5ab443344c59cd1f930337ba773",
      "a99cf01bf9044f349ceddcde0d2af21e",
      "88e5c68c74324253868e8f5071b39a54",
      "c4b9a01fa69f4734bbd2a7e0c0014f7d",
      "839b037658dd4c55a3aca638288a4e85",
      "69891300036a4ef5bf5ee48e3527605c",
      "da41a36b7e514bdc9b065e58cd33eb05",
      "62192e7794b54c5eb3482b533fb620c0",
      "b0f4587d564441bb90464ce5d5393ebc",
      "91fe390011b64e44bdbdbef3aa7611b9",
      "990daf1ba27d4a82b0c986eee4895786",
      "a3b31b5ff4594ae5b58f8f9aa8f714c6",
      "bd2230c066bd4edcad0e6483a71a5e7b",
      "886ee2fda8324d8cb6a99db21d9bd33d",
      "bb29f089116d41229972d1c5af8f73e4"
     ]
    },
    "id": "7c9a9883",
    "outputId": "6a8b9b3c-8ff0-409c-f591-9e94d031a87f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth 2025.11.2: Fast Llama patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59936955b20743dfa9f8b67003be7845"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/158 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc3c36fc9b534c86bc7af600b9e1382a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d35760966bc48ad8602333f83060c57"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e150cf7577754fcdb0ae7b2d1b9cd42d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec0711350cf848fb839806e318b83298"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae52abee96f945408cf06621b733caec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/742 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1d8cdd394004cca86a5ff7449361f3f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "839b037658dd4c55a3aca638288a4e85"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.11.2 patched 30 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model loaded with LoRA adapters attached.\n"
     ]
    }
   ],
   "source": [
    "# Load model for continued pretraining\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name='unsloth/smollm2-135m',\n",
    "    dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "# Small memory helpers\n",
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Make sure we have a pad token (for batching)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Attach LoRA adapters so training is allowed on a quantized model\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=8,                      # smaller rank = lighter/faster\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n",
    ")\n",
    "print(\"Model loaded with LoRA adapters attached.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a3f612",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "baebae555ebb4314bbf19974d5d36176",
      "3ac6dcb291c04bb182a2c4773afdae13",
      "44e5c7eaacc9457d88a2b15d9abc2a2e",
      "a5b07c9f405e48ec8de3098d3543203d",
      "94388cf525424c25b09c2ae886f87ac7",
      "aa080f11bf6c4cdab7cb158c89d54f1f",
      "75db2c2db3cf4275bbdbc5fa4e6a2261",
      "5d8f314a3ad3403ca726ddc0fd021cec",
      "c1b3967727e744038119d34c1950ba89",
      "ac847bf98e40436f815bcbc85169c424",
      "da76fa66471046c099ee0e6a98dd1b6f"
     ]
    },
    "id": "62a3f612",
    "outputId": "c854e7aa-a43e-4d6a-d099-1a63989c11c5"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "baebae555ebb4314bbf19974d5d36176"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Tokenize the dataset for language modeling\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=256)\n",
    "\n",
    "tokenized_dataset = text_ds.map(tokenize_function, batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f72f86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "56f72f86",
    "outputId": "5be62ce3-27cc-4b34-9ec6-58397c510814"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 100,000 | Num Epochs = 1 | Total steps = 1,000\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 1 x 1) = 2\n",
      " \"-____-\"     Trainable parameters = 2,442,240 of 136,957,824 (1.78% trained)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 09:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.197800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.109500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.093600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.159900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.131000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.122400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.139200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.078200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.183600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.063300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.962800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.047600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.077700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.050100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.127300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.121200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.996800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.992800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.941600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.993900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.944500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.975400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.899000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.044600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.029100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.973400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.131700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.993300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.074600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.199500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.089200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.912800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.955600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.075900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.143200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.044100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.041100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.893000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.084500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.982500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.964100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.073100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.976900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.938000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.983500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.999300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.926100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.123200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=2.039666751861572, metrics={'train_runtime': 553.1589, 'train_samples_per_second': 3.616, 'train_steps_per_second': 1.808, 'total_flos': 333759578112000.0, 'train_loss': 2.039666751861572, 'epoch': 0.02})"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Setup Trainer for continued pretraining\n",
    "from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./smollm2_continued_pretrain_hi',\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    max_steps=1000,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a09b80",
   "metadata": {
    "id": "e8a09b80",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8e1a60db-5105-4a2e-a9ae-d03663d3c98f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Continued pretraining complete.\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('./smollm2_continued_pretrain_hi')\n",
    "tokenizer.save_pretrained('./smollm2_continued_pretrain_hi')\n",
    "print('Continued pretraining complete.')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test the continued-pretrained model\n",
    "print(\"\\nTesting the continued-pretrained model...\\n\")\n",
    "\n",
    "# Example Hindi sentence prompt\n",
    "prompt_hi = \"à¤­à¤¾à¤°à¤¤ à¤•à¥€ à¤°à¤¾à¤œà¤§à¤¾à¤¨à¥€ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?\"\n",
    "\n",
    "# Tokenize and generate output\n",
    "inputs = tokenizer(prompt_hi, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "\n",
    "# Decode and print\n",
    "print(\"Input:\", prompt_hi)\n",
    "print(\"Model output:\\n\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ],
   "metadata": {
    "id": "6BnrRHtDSSrb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "428c5ac1-e737-42c1-9de6-92aa9fdab720"
   },
   "id": "6BnrRHtDSSrb",
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Testing the continued-pretrained model...\n",
      "\n",
      "Input: à¤­à¤¾à¤°à¤¤ à¤•à¥€ à¤°à¤¾à¤œà¤§à¤¾à¤¨à¥€ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?\n",
      "Model output:\n",
      " à¤­à¤¾à¤°à¤¤ à¤•à¥€ à¤°à¤¾à¤œà¤§à¤¾à¤¨à¥€ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ? à¤œà¥‹ à¤¹à¤®à¥‡à¤‚ à¤¹à¤®à¥‡à¤‚ à¤¹à¤®à¥‡à¤‚ à¤¹à¤®à¥‡à¤‚ à¤¹à¤®à¥‡à¤‚ à¤¹à¤®à¥‡à¤‚ à¤¹à¤®à¥‡à¤‚ à¤¹à¤®à¥‡à¤‚ à¤¹à¤®à¥‡à¤‚ à¤¹\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "L4"
  },
  "accelerator": "GPU",
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}